\documentclass[spanish,11pt,letterpaper]{article}

\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
% \usepackage{listings}
% \usepackage{xcolor}
\renewcommand{\vec}[1]{\mathbf{#1}}
\decimalpoint

\title{Clasificación de canciones por género en base a la música\\
usando aprendizaje colectivo}
\author{Hernández Chiapa David Felipe\\
López García Gilberto Isaac}
\affil{Facultad de Ciencias\\{\small Universidad Nacional Autónoma de México}}
\date{\small\today}

\begin{document}

\maketitle

\section{Introducción}

En el primer proyecto, \textit{Sistema de clasificación automática de documentos,
Clasificación de canciones por género en base a la letra}, atacamos el problema
de clasificación de canciones por género basándonos solo en la letra
asumiendo que el léxico tendría un gran peso sobre el género. Esta
forma de enfrentar el problema no dió buenos resultados pues nuestros algoritmos
de clasificación tenía un porcentaje de acierto de entre 50 y 60 por ciento,
básicamente estaban adivinando al azar.

En el presente trabajo usaremos audio para la clasificación, usando un clasificador
colectivo compuesto de redes convolucionales sobre los espectrogramas de la música,
pues no solo la letra sino el sonido es necesario para determinar el género de
una pieza musical.

\section{Definición del problema}

\subsection{Espectrogramas}

Un espectrograma es una representación visual de una señal como el sonido, que
guarda información sobre el espectro de frecuencias y su variación en el tiempo.
Viendo el sonido como una función del tiempo, un espectrograma se puede obtener
mediante la Transformada de Fourier de esa señal, para obtener las frecuencias
que componen la señal y sus amplitudes. Esta información queda codificada como una
imagen donde cada pixel con coordenadas $(t,f)$, donde $t$ es una posición en el
tiempo (un intervalo pequeño pues la señal debe discretizarse para ser procesada
por la computadora) y $f$ una frecuencia, tiene un valor que corresponde a la
amplitud y se muestra como un color (ver Figura \ref{fig:specgram}).

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{specgram_classical.png}
\includegraphics[width=0.9\textwidth]{specgram_metal.png}
\caption{Espectrograma de una canción `classical' (arriba) y `metal' (abajo).}
\label{fig:specgram}
\end{figure}

La amplitud puede estar en escala lineal o logarítmica (por ejemplo, decibeles).
Normalmente se escoge escala logarítmica, escala que usamos aquí.

Los espectrogramas son una representación muy usada para distintas tareas como
música, sonares, radares, procesamiento del habla, y en años recientes, para
identificar eventos en muestras de sonido como en \cite{audio_recognition}.

\section{Aprendizaje colectivo}

En el proyecto \textit{Is this Loss? Sistema de reconocimiento de objetos en
imágenes} ya se habló de las redes convolucionales por lo que aquí se omite su
discusión y procedemos a hablar de clasificadores colectivos.

El aprendizaje colectivo, en inglés \textit{ensemble learning}\footnote{Traducción
del término adoptada por los autores del presente escrito.}, es el proceso de usar
distintos modelos, ya sean clasificadores o expertos, generados y combinados
estratégicamente para lograr un mejor desempeño en tareas de predicción (clasificación
o regresión).

Un clasificador colectivo es un clasificador cuya predicción está en función de
las predicciones individuales de los modelos que lo componen. Se usan principalmente
para mejorar el desempeño individual de los modelos en conjunto, evitar seleccionar y trabajar
con un clasificador pobre y asignar una ``confianza'' a las decisiones hechas
por los modelos individuales\cite{scholarpedia}.

\subsection{Bagging}

El clasificador colectivo que usaremos es \textit{Bagging}\footnote{Bootstrap
aggregation.}, un clasificador simple e intuitivo que ha demostrado tener un buen
desempeño (obviamente, esto si sus componentes tienen buen desempeño). Bagging
consiste en entrenar clasificadores independientemente sobre muestras aleatorias
con reemplazo del dataset y clasificar entradas por mayoría de votos en las
clasificaciones individuales de sus componentes. El algoritmo a continuación:\\
\textbf{Entrada:}
\begin{itemize}
  \item Conjunto de entrenamiento $S$ con conjunto de etiquetas
  $\{\ell_1,\ldots,\ell_m\}$ para $m$ clases distintas.
  \item Clasificadores que lo componen $C_1,\ldots,C_k$.
  \item Porcentaje $F$ de los datos que se usarán para entrenar a cada clasificador.
\end{itemize}
\textbf{Entrenamiento:} Para cada clasificador $C_i$:
\begin{enumerate}
  \item Tomar una muestra aleatoria con remplazo $S_i$ de $S$ con tamaño $F$ por
  ciento el tamaño de $S$.
  \item Entrenar el clasificador $C_i$ con el conjunto $S_i$.
\end{enumerate}
\textbf{Clasificación:} Dada una entrada $\vec{x}$:
\begin{enumerate}
  \item Evaluar cada componente $C_i$ con $\vec{x}$ para obtener una clase $y_i$.
  \item Para cada clase $\ell_1,\ldots,\ell_m$, contar el número de etiquetas
  resultantes de las predicciones de los clasificadores.
  \item La etiqueta $y$ para $\vec{x}$ es aquella clase que tuvo el mayor conteo
  en el paso anterior.
\end{enumerate}

\subsection{Intuición}

El propósito detrás de tomar subconjuntos $S_i$ para cada clasificador $C_i$ es
tener diversidad en lo aprendido por los clasificadores indivualmente, y por lo
tanto, diversidad en sus respuestas. Tener diversidad en los componentes de un
clasificador colectivo nos ayuda a corregir errores hechos por algunos de estos;
los clasificadores cometen distintos errores en distintas entradas, pero en conjunto
deciden la ``mejor'' clasificación.

En este caso, usando bagging, la respuesta del clasificador colectivo no tiene
que ser la respuesta correcta, pero es la mejor respuesta en el sentido que
tuvo mayor cantidad de votos, esto es, el clasificador confía en que es la
respuesta correcta basado en las respuestas de sus componentes y el conocimiento
que tienen.

Si la gran mayoría de los clasificadores responden lo mismo decimos que el clasificador
colectivo tiene alta confianza en su respuesta, en otro caso, si las respuestas
no coinciden decimos que el clasificador tiene baja confianza en su respuesta.
Una respuesta con alta confianza no tiene por que ser correcta, y una con baja
confianza no tiene que ser incorrecta, pero si los componentes fueron propiamente
entrenados, en general una respuesta con alta confianza es correcta y con baja
confianza incorrecta\cite{scholarpedia}.

\section{Datos y preprocesamiento}

El dataset para el proyecto es \textsf{GTZAN Genre Collection}%
\footnote{\url{http://marsyasweb.appspot.com/download/data_sets/}}, que consiste de
una colección de 1000 clips de canciones con una duración de 30 segundos cada uno,
clasificados en 10 géneros musicales distintos: blues, classical, country, disco,
hiphop, jazz, metal, pop, reggae y rock, 100 clips por género.

Se obtuvo el espectrograma de estos clips, y estos espectrogramas (imágenes
\texttt{.png}) son los datos que se usaron para realizar una clasificación con
redes convolucionales.

Los espectrogramas obtenidos son arreglos de 3 dimensiones: tiempo, frecuencia
y amplitud. A la amplitud aplicamos logaritmo base 10 para tener una escala en
decibeles.

\section{Experimentación}

\section{Resultados}

\section{Conclusiones}

\begin{thebibliography}{9}
\bibitem{scholarpedia}
Ensemble Learning. (2009). Obtenido de
\url{http://www.scholarpedia.org/article/Ensemble_learning}

\bibitem{audio_recognition}
Phan, H., Hertel, L., Maass, M., \& Mertins, A. (2016).
Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural Networks.
arXiv:1604.06338v2

\end{thebibliography}


\end{document}
